{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODgr8Vbkj4rp+Elyuu2a06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohdammar128/DeepLearning-/blob/main/cnn_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About Datasets and library\n",
        "\n",
        "1.   Here I have used cifar datasets having 10 classes\n",
        "2.   I am using pytorch library for this\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_Dis4gL3WWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#for preparing data and transformation as well as normalization\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bQ315Ah35KB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data preparation and Normalization**"
      ],
      "metadata": {
        "id": "2vgZZDn6D5ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1. transforms.ToTensor():** This converts the input image (PIL Image or numpy array) to a PyTorch tensor. It also scales the pixel values from [0, 255] to [0, 1].\n",
        "\n",
        "**2.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)):** This normalizes the tensor image with mean (0.5, 0.5, 0.5) and standard deviation (0.5, 0.5, 0.5) for each of the three color channels. This helps in improving the training process of the model.\n",
        "\n",
        "**3. The transforms.Compose** function chains these two transformations together. So, first the image is converted to a tensor, and then it is normalized.\n",
        "\n"
      ],
      "metadata": {
        "id": "mgQJ1bMf6rui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting dataset into tensor normalized form\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
      ],
      "metadata": {
        "id": "Q3ZxDdLA5n48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing cifr datasets\n",
        "train_data=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "test_data=datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n"
      ],
      "metadata": {
        "id": "GB6Bkvs46MuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Batch size\n",
        "A batch size of 20 means that during each training iteration, the model will process 20 samples at a time to compute the loss and update its parameters.\n",
        "\n",
        "This means:\n",
        "\n",
        "20 images will be passed through the model simultaneously in each forward pass.\n",
        "The gradients will be calculated based on the average loss over these 20 images.\n",
        "The model's weights will be updated once per batch, based on these calculated gradients.\n",
        "\n",
        "---\n",
        "### np.random.shuffle(indices)\n",
        "np.random.shuffle(indices): This function shuffles the elements of the indices array randomly. This is often done before splitting a dataset to ensure that the training and validation/test sets have a similar distribution of samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "MFpxtctd892Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=20\n",
        "num_workers=0 #it is used for parallel processing (if you have multiple core )\n",
        "num_train=len(train_data)\n",
        "print(f\"num_train: {num_train}\")\n",
        "indices=list(range(num_train))\n",
        "print(f\"indices: {indices[49998:50000]}\")\n",
        "np.random.shuffle(indices)\n",
        "print(f\"shuffled Indices: {indices[:5]}\")\n",
        "split=int(np.floor(0.2*num_train)) #20 percent of total image\n",
        "train_idx,valid_idx=indices[split:],indices[:split]\n"
      ],
      "metadata": {
        "id": "P_f5MpHn8BnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler=SubsetRandomSampler(train_idx)\n",
        "valid_sampler=SubsetRandomSampler(valid_idx)\n",
        "\n",
        "#prepare dataloader (combiner dataset and sample)\n",
        "train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,sampler=train_sampler,num_workers=num_workers)\n",
        "valid_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,sampler=valid_sampler,num_workers=num_workers)\n",
        "test_loader=torch.utils.data.DataLoader(test_data,batch_size=batch_size,num_workers=num_workers)\n",
        "\n",
        "classes=[ 'airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "metadata": {
        "id": "f7aNiOPR8o_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"type of train loader {type(train_loader)}\")\n",
        "print(f\"type of valid loader {type(valid_loader)}\")\n",
        "print(f\"type of test loader {type(test_loader)}\")"
      ],
      "metadata": {
        "id": "EMwXd3uFCeHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualizing train images**"
      ],
      "metadata": {
        "id": "jYrYNpK6DoBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain one batch of training data\n",
        "dataiter=iter(train_loader)\n",
        "images,labels=next(dataiter)\n",
        "print(f\"shape of images: {images.shape}\")\n",
        "print(f\"shape of labels: {labels.shape}\")\n",
        "images=images.numpy()     #(batchsize,channel,height,widht)\n",
        "print(f\"shape of images: {images.shape}\")\n",
        "def helper(img):\n",
        "  img=img*0.5+0.5\n",
        "  npimg=img.numpy()\n",
        "  print(f\"shape of image: {npimg.shape}\")\n",
        "  plt.imshow(np.transpose(npimg,(1,2,0))) #(channel,height,width)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "oASyryiGD2yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you have an image tensor with shape (3, 28, 28), representing an RGB image with 3 channels and dimensions 28x28. When you use np.transpose(npimg, (1, 2, 0)), it will rearrange the dimensions to (28, 28, 3), which is compatible with plt.imshow()."
      ],
      "metadata": {
        "id": "ucyA4JgXIBHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imgshow(img):\n",
        "  ## Unnormalize\n",
        "  ##image = image * std + mean\n",
        "  img=img*0.5+0.5\n",
        "\n",
        "  plt.imshow(np.transpose(img,(1,2,0))) #convert from tensor image , (1,2,0)==(channel,height,width)\n"
      ],
      "metadata": {
        "id": "lF5SQE_iFVX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(25,4))\n",
        "for idx in np.arange(20):\n",
        "  ax=fig.add_subplot(2,10,idx+1,xticks=[],yticks=[])\n",
        "  imgshow(images[idx])\n",
        "  ax.set_title(classes[labels[idx]])"
      ],
      "metadata": {
        "id": "T21Tp_xhICRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator=iter(train_loader)\n",
        "images,labels=next(iterator)\n",
        "print(f\"shape of images: {images.shape}\")\n",
        "print(f\"shape of labels: {labels.shape}\")"
      ],
      "metadata": {
        "id": "p3XBb5gwG9zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].shape"
      ],
      "metadata": {
        "id": "rg5u44sdTSH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculte_size_conv(Input_height,kernel_size,stride=1,padding=1):\n",
        "  return ((Input_height-kernel_size+2*padding)/stride)+1\n",
        "\n",
        "def calculte_size_pool(Input_height,kernel_size,stride=2):\n",
        "  return ((Input_height-kernel_size)/stride)+1\n"
      ],
      "metadata": {
        "id": "EfK5G7dXeF-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height=32\n",
        "wight=32\n",
        "res=calculte_size_conv(height,3)\n",
        "print(res)\n",
        "res=calculte_size_pool(res,2)\n",
        "print(res)\n",
        "res=calculte_size_conv(res,3)\n",
        "print(res)\n",
        "res=calculte_size_pool(res,2)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "BWdaG3wAevvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN,self).__init__()\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
        "    self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "    self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    #linear layer (64*4*4,500)\n",
        "    self.fc1=nn.Linear(64*4*4,500) # first hidden layer\n",
        "    self.fc2=nn.Linear(500,10) # second hidden layer\n",
        "    self.dropout=nn.Dropout(0.25)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.maxpool(F.relu(self.conv1(x))) #here relu function is applid to make negative value 0 in other term to add non-linarity in the model\n",
        "    x=self.maxpool(F.relu(self.conv2(x)))\n",
        "    x=self.maxpool(F.relu(self.conv3(x)))\n",
        "\n",
        "    x=x.view(-1,64*4*4)\n",
        "    x=self.dropout(x)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=self.dropout(x)\n",
        "    x=self.fc2(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gB1UWOimT4cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting Single Image"
      ],
      "metadata": {
        "id": "E9_a3YHxfEQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SimpleCNN()\n",
        "print(f\"model: {model}\")"
      ],
      "metadata": {
        "id": "io1cbYyHAgRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cirterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "3FjgL9Acs5nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model.load_state_dict(torch.load('model_cifar.pt'))"
      ],
      "metadata": {
        "id": "xsYrE1w-AVgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "n_epochs = 10\n",
        "valid_loss_min = np.Inf  # Track minimum validation loss\n",
        "## Keeping track of training and validation loss\n",
        "for epoch in range(1, n_epochs + 1):  # Corrected range\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    ## Train the model\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "        # Calculating the output for each batch\n",
        "        output = model(data)\n",
        "        # Calculating the loss\n",
        "        loss = cirterion(output, target)  # Fixed typo 'cirterion' -> 'criterion'\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update the parameters\n",
        "\n",
        "        # Accumulate training loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "    ## Validate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # No need to compute gradients during validation\n",
        "        for data, target in valid_loader:\n",
        "            output = model(data)\n",
        "            loss =cirterion(output, target)\n",
        "            valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "    # Calculate average losses\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "\n",
        "    print(f\"Epoch: {epoch}\\tTraining Loss: {train_loss:.6f}\\tValidation Loss: {valid_loss:.6f}\")\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(\n",
        "            valid_loss_min, valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss\n"
      ],
      "metadata": {
        "id": "TY8ZSfIptKiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "ziEF9dYX20QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_pred=transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        " ])"
      ],
      "metadata": {
        "id": "mZVJDD_e6fql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(url):\n",
        "    # Step 1: Fetch the image from the URL\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error fetching image\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Open the image using BytesIO\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    print(f\"Image size: {img.size}\")  # Print size of the image\n",
        "\n",
        "    # Step 3: Transform the image\n",
        "    img_transformed = transform_pred(img)  # Make sure transform_pred is defined\n",
        "    img_transformed = img_transformed.unsqueeze(0)  # Add batch dimension\n",
        "    print(f\"Shape of image: {img_transformed.shape}\")\n",
        "\n",
        "    # Step 4: Make prediction\n",
        "    with torch.no_grad():  # Disable gradient calculations\n",
        "        output = model(img_transformed)  # Pass the image through the model\n",
        "\n",
        "        # Step 5: Apply softmax to get probabilities\n",
        "        probabilities = F.softmax(output, dim=1)\n",
        "        print(f\"Probabilities: {probabilities}\")\n",
        "\n",
        "        # Step 6: Get the predicted class\n",
        "        predicted_class = torch.argmax(probabilities, dim=1)\n",
        "        print(f\"Predicted class index: {predicted_class.item()}\")\n",
        "\n",
        "    # Step 7: Return the predicted class label\n",
        "    return classes[predicted_class.item()]  # Make sure 'classes' is defined\n",
        "\n",
        "# Example usage\n",
        "url = \"https://img.freepik.com/free-vector/adorable-wideeyed-kitten-illustration_1308-164226.jpg\"\n",
        "predicted_label = predict_image(url)\n",
        "print(f\"Predicted label: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "97iTc3HT-UpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}